name: Backend Tests & Quality

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: "3.11"

jobs:
  test:
    runs-on: ubuntu-latest
    
    # Use environment variables instead of hardcoded secrets
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL_TEST || 'postgresql://test_user:test_password@localhost:5432/test_db' }}
      CLERK_WEBHOOK_SECRET: ${{ secrets.CLERK_WEBHOOK_SECRET_TEST || 'test_webhook_secret' }}
      CLERK_ISSUER_URL: ${{ secrets.CLERK_ISSUER_URL_TEST || 'https://test.clerk.accounts.dev' }}
      ADMIN_SECRET_KEY: ${{ secrets.ADMIN_SECRET_KEY_TEST || 'test_admin_secret_key_for_ci' }}
    
    services:
      postgres:
        image: postgis/postgis:15-3.4
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-cov pytest-html pytest-json-report

    - name: Wait for PostgreSQL
      run: |
        until pg_isready -h localhost -p 5432 -U test_user; do
          echo "Waiting for postgres..."
          sleep 2
        done

    - name: Create reports directory
      run: mkdir -p reports

    - name: Run database migrations/setup
      run: |
        python -c "
        from app.database import engine
        from app import models
        models.Base.metadata.create_all(bind=engine)
        print('Database tables created successfully')
        "

    - name: Run tests with coverage
      run: |
        pytest \
          --cov=app \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --html=reports/report.html \
          --self-contained-html \
          --json-report --json-report-file=reports/report.json \
          -v \
          tests/

    - name: Upload coverage reports to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: backend
        name: codecov-backend
        token: ${{ secrets.CODECOV_TOKEN }}

    - name: Upload test artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-reports-${{ github.run_id }}
        path: reports/

  lint:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install linting tools
      run: |
        python -m pip install --upgrade pip
        pip install ruff mypy bandit safety

    - name: Run Ruff Check (Linting)
      run: ruff check app/ tests/

    - name: Run Ruff Format (Formatting Check)
      run: ruff format --check app/ tests/

    - name: Run MyPy (Type Checking)
      run: mypy app/ --ignore-missing-imports
      continue-on-error: true

    - name: Run Bandit (Security Linting)
      run: |
        bandit -r app/ -f json -o bandit-report.json || true
        if [ -f bandit-report.json ]; then
          echo "Bandit report generated"
        fi
      continue-on-error: true

    - name: Run Safety (Dependency Security Check)
      run: |
        safety check --json --output safety-report.json || true
        if [ -f safety-report.json ]; then
          echo "Safety report generated"
        fi
      continue-on-error: true

    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports-${{ github.run_id }}
        path: "*-report.json"

  performance:
    runs-on: ubuntu-latest
    needs: test
    
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL_TEST || 'postgresql://test_user:test_password@localhost:5432/test_db' }}
      CLERK_WEBHOOK_SECRET: ${{ secrets.CLERK_WEBHOOK_SECRET_TEST || 'test_webhook_secret' }}
      CLERK_ISSUER_URL: ${{ secrets.CLERK_ISSUER_URL_TEST || 'https://test.clerk.accounts.dev' }}
      ADMIN_SECRET_KEY: ${{ secrets.ADMIN_SECRET_KEY_TEST || 'test_admin_secret_key_for_ci' }}
    
    services:
      postgres:
        image: postgis/postgis:15-3.4
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install locust

    - name: Wait for PostgreSQL
      run: |
        until pg_isready -h localhost -p 5432 -U test_user; do
          echo "Waiting for postgres..."
          sleep 2
        done

    - name: Setup database
      run: |
        python -c "
        from app.database import engine
        from app import models
        models.Base.metadata.create_all(bind=engine)
        print('Performance test database setup complete')
        "

    - name: Create performance test directory
      run: mkdir -p tests/performance

    - name: Create Locustfile if missing
      run: |
        if [ ! -f tests/performance/locustfile.py ]; then
          cat > tests/performance/locustfile.py << 'EOF'
        from locust import HttpUser, task, between
        import json

        class BackendUser(HttpUser):
            wait_time = between(1, 3)
            
            def on_start(self):
                """Setup method called once per user"""
                self.client.get("/health")

            @task(3)
            def health_check(self):
                """Test health endpoint"""
                self.client.get("/health")
            
            @task(2) 
            def get_alerts(self):
                """Test alerts listing endpoint"""
                self.client.get("/alerts/")
            
            @task(1)
            def get_nearby_alerts(self):
                """Test nearby alerts endpoint"""
                self.client.get("/alerts/nearby?lat=37.7749&lon=-122.4194&radius_km=5")
        EOF
        fi

    - name: Run performance tests
      run: |
        # Start the server in background
        uvicorn app.main:app --host 0.0.0.0 --port 8000 &
        SERVER_PID=$!
        
        # Wait for server to start
        sleep 15
        
        # Check if server is running
        curl -f http://localhost:8000/health || (echo "Server failed to start" && exit 1)
        
        # Run load tests
        locust -f tests/performance/locustfile.py --host=http://localhost:8000 --users 20 --spawn-rate 2 --run-time 30s --html performance_report.html --headless
        
        # Clean up
        kill $SERVER_PID || true

    - name: Upload performance report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-report-${{ github.run_id }}
        path: performance_report.html
